{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from siamese import SiameseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_dir = \"sign_data_ver1/train\"\n",
    "test_dir = \"sign_data_ver1/test\"\n",
    "train_csv = \"sign_data_ver1/train_data.csv\"\n",
    "test_csv =  \"sign_data_ver1/test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset():\n",
    "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.train_df=pd.read_csv(training_csv)\n",
    "        self.train_df.columns =[\"image1\",\"image2\",\"label\"]\n",
    "        self.train_dir = training_dir    \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        # getting the image path\n",
    "        image1_path=os.path.join(self.train_dir, self.train_df.iat[index,0])\n",
    "        image2_path=os.path.join(self.train_dir, self.train_df.iat[index,1])\n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        return img0, img1 , torch.from_numpy(np.array([int(self.train_df.iat[index,2])],dtype=np.float32))\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.9804, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         ...,\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843]]]), tensor([[[0.9843, 0.9843, 0.9804,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9804, 0.9843,  ..., 0.9843, 0.9804, 0.9804],\n",
      "         [0.9843, 0.9843, 0.9843,  ..., 0.9804, 0.9804, 0.9804],\n",
      "         ...,\n",
      "         [0.9843, 0.9843, 0.9804,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9804,  ..., 0.9843, 0.9843, 0.9843],\n",
      "         [0.9843, 0.9843, 0.9804,  ..., 0.9843, 0.9843, 0.9843]]]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "# Load the the dataset from raw image folders\n",
    "siamese_dataset = SiameseDataset(train_csv,train_dir,\n",
    "                                transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                            transforms.ToTensor()\n",
    "                                                            ])\n",
    "                                )\n",
    "\n",
    "\n",
    "print(siamese_dataset[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a siamese network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "        )\n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128,2))\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        diff = x0 - x1\n",
    "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "\n",
    "        mdist = self.margin - dist\n",
    "        dist = torch.clamp(mdist, min=0.0)\n",
    "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Declare Siamese Network\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m net \u001b[39m=\u001b[39m SiameseNetwork()\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m      3\u001b[0m \u001b[39m# Decalre Loss Function\u001b[39;00m\n\u001b[0;32m      4\u001b[0m criterion \u001b[39m=\u001b[39m ContrastiveLoss()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    672\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \n\u001b[0;32m    674\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 688\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 601\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    602\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    672\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \n\u001b[0;32m    674\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 688\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\cuda\\__init__.py:216\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[39m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[39m# are found or any other error occurs\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[0;32m    217\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    220\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Declare Siamese Network\n",
    "net = SiameseNetwork().cuda()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "#train the model\n",
    "def train():\n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for epoch in range(1,config.epochs):\n",
    "        for i, data in enumerate(train_dataloader,0):\n",
    "            img0, img1 , label = data\n",
    "            optimizer.zero_grad()\n",
    "            output1,output2 = net(img0,img1)\n",
    "            loss_contrastive = criterion(output1,output2,label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()    \n",
    "        print(\"Epoch {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "        iteration_number += 10\n",
    "        counter.append(iteration_number)\n",
    "        loss.append(loss_contrastive.item())\n",
    "    show_plot(counter, loss)   \n",
    "    return net\n",
    "#set the device to cuda\n",
    "device = torch.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "model = train()\n",
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "print(\"Model Saved Successfully\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac209536f6acf79e580d00c1ac3090d6f4178d82fa7a9c4f4edd3c5b57d297d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
