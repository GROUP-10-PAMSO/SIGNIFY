{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>068/09_068.png</th>\n",
       "      <th>068_forg/03_0113068.PNG</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>068/09_068.png</td>\n",
       "      <td>068_forg/01_0124068.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>068/09_068.png</td>\n",
       "      <td>068_forg/02_0124068.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>068/09_068.png</td>\n",
       "      <td>068_forg/01_0113068.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>068/09_068.png</td>\n",
       "      <td>068_forg/04_0124068.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068/09_068.png</td>\n",
       "      <td>068_forg/04_0113068.PNG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   068/09_068.png  068_forg/03_0113068.PNG  1\n",
       "0  068/09_068.png  068_forg/01_0124068.PNG  1\n",
       "1  068/09_068.png  068_forg/02_0124068.PNG  1\n",
       "2  068/09_068.png  068_forg/01_0113068.PNG  1\n",
       "3  068/09_068.png  068_forg/04_0124068.PNG  1\n",
       "4  068/09_068.png  068_forg/04_0113068.PNG  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sign_data_ver1/train_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sign_data_ver1/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 12308/23205 [01:39<01:27, 124.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m img2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img2)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n\u001b[0;32m     10\u001b[0m img1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img1, (\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m), cv2\u001b[39m.\u001b[39mINTER_CUBIC)\n\u001b[1;32m---> 11\u001b[0m img2 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img2, (\u001b[39m128\u001b[39;49m,\u001b[39m128\u001b[39;49m), cv2\u001b[39m.\u001b[39;49mINTER_CUBIC)\n\u001b[0;32m     12\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [[img1, img2]]\n\u001b[0;32m     13\u001b[0m y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [df[\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m][ind]]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for ind in tqdm(df.index):\n",
    "    name1 = df['068/09_068.png'][ind]\n",
    "    name2 = df['068_forg/03_0113068.PNG'][ind]\n",
    "    img1 = cv2.cvtColor(cv2.imread(path+str(name1)), cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(cv2.imread(path+str(name2)), cv2.COLOR_BGR2GRAY)\n",
    "    img1 = np.array(img1).astype('float32')/255\n",
    "    img2 = np.array(img2).astype('float32')/255\n",
    "    img1 = cv2.resize(img1, (128,128), cv2.INTER_CUBIC)\n",
    "    img2 = cv2.resize(img2, (128,128), cv2.INTER_CUBIC)\n",
    "    x += [[img1, img2]]\n",
    "    y += [df['1'][ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = x[:17000,0]\n",
    "x_train2 = x[:17000,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input((128, 128, 1))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(32, (5, 5), activation=\"relu\",kernel_regularizer=regularizers.L2(l2=2e-4),\n",
    "    bias_regularizer=regularizers.L2(2e-4))(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(32, (5, 5),kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.L2(2e-4), activation=\"relu\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "embedding_network = tf.keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((128, 128, 1))\n",
    "input_2 = layers.Input((128, 128, 1))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          3578980     ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1)           4           ['lambda[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,578,986\n",
      "Trainable params: 3,525,158\n",
      "Non-trainable params: 53,828\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "siamese.load_weights(\"siamese_model1.h5\")\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.fit(\n",
    "    [x_train1, x_train2],\n",
    "    y,\n",
    "    validation_split = 0.1,\n",
    "    batch_size = 32,\n",
    "    epochs = 10,\n",
    "    verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac209536f6acf79e580d00c1ac3090d6f4178d82fa7a9c4f4edd3c5b57d297d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
