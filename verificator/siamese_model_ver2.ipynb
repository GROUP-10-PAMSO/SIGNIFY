{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"sign_data_ver1/train\"\n",
    "test_dir = \"sign_data_ver1/test\"\n",
    "train_csv = \"sign_data_ver1/train_data.csv\"\n",
    "test_csv =  \"sign_data_ver1/test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# Note: Implement a shuffle system\n",
    "\n",
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, csv = None, dir = None, batch_size = None, resize = None):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.df.columns = [\"img1\", \"img2\", \"label\"]\n",
    "\n",
    "        self.img1 = self.df[\"img1\"]\n",
    "        self.img2 = self.df[\"img2\"]\n",
    "        self.label = self.df[\"label\"]\n",
    "\n",
    "        self.dir = dir\n",
    "        self.resize = resize\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_x1 = self.img1[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x2 = self.img2[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_y = self.label[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        X1, X2 = [], []\n",
    "        for x1, x2 in zip(batch_x1, batch_x2):\n",
    "            img1_path = os.path.join(self.dir, x1)\n",
    "            img2_path = os.path.join(self.dir, x2)\n",
    "\n",
    "            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if self.resize is not None:\n",
    "                img1 = cv2.resize(img1, (self.resize))\n",
    "                img2 = cv2.resize(img2, (self.resize))\n",
    "\n",
    "            X1.append(img1)\n",
    "            X2.append(img2)\n",
    "\n",
    "        return [np.array(X1), np.array(X2)], np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import *\n",
    "# from keras.models import Model, Sequential \n",
    "\n",
    "# img1_inp = Input((train_data.resize),name=\"img1_inp\")\n",
    "# img2_inp = Input((train_data.resize),name=\"img2_inp\")\n",
    "\n",
    "# network = Sequential()\n",
    "\n",
    "# network.add(Conv2D(64,(3,3),input_shape=(224, 224, 1),activation='relu'))\n",
    "# network.add(MaxPooling2D(3, strides=2))\n",
    "\n",
    "# network.add(Conv2D(32,(3,3),activation='relu'))\n",
    "# network.add(MaxPooling2D(2,2))\n",
    "\n",
    "# network.add(Flatten())\n",
    "# network.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "# feature_vector_1 = network(img1_inp)\n",
    "# feature_vector_2 = network(img2_inp)\n",
    "\n",
    "# concat = Concatenate()([feature_vector_1, feature_vector_2])\n",
    "# dense = Dense(128, activation='relu')(concat)\n",
    "# output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "# network = Model(inputs=[img1_inp, img2_inp], outputs=output)\n",
    "# network.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras import regularizers\n",
    "\n",
    "input = layers.Input((128, 128, 1))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(32, (5, 5), activation=\"relu\",kernel_regularizer=regularizers.L2(l2=2e-4),\n",
    "    bias_regularizer=regularizers.L2(2e-4))(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(32, (5, 5),kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.L2(2e-4), activation=\"relu\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "embedding_network = tf.keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((128, 128, 1))\n",
    "input_2 = layers.Input((128, 128, 1))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          3578980     ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1)           4           ['lambda[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,578,986\n",
      "Trainable params: 3,525,158\n",
      "Non-trainable params: 53,828\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# network.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "siamese.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "726/726 [==============================] - 927s 1s/step - loss: 0.7319 - accuracy: 0.5287 - val_loss: 0.4942 - val_accuracy: 0.8845\n",
      "Epoch 2/10\n",
      "726/726 [==============================] - 903s 1s/step - loss: 0.6953 - accuracy: 0.5465 - val_loss: 0.5712 - val_accuracy: 0.8457\n",
      "Epoch 3/10\n",
      "726/726 [==============================] - 915s 1s/step - loss: 0.6910 - accuracy: 0.5513 - val_loss: 0.6086 - val_accuracy: 0.7797\n",
      "Epoch 4/10\n",
      "726/726 [==============================] - 911s 1s/step - loss: 0.6879 - accuracy: 0.5573 - val_loss: 0.5463 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "726/726 [==============================] - 933s 1s/step - loss: 0.6861 - accuracy: 0.5588 - val_loss: 0.5311 - val_accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "726/726 [==============================] - 914s 1s/step - loss: 0.6854 - accuracy: 0.5619 - val_loss: 0.5027 - val_accuracy: 0.7125\n",
      "Epoch 7/10\n",
      "726/726 [==============================] - 920s 1s/step - loss: 0.6846 - accuracy: 0.5614 - val_loss: 0.5339 - val_accuracy: 0.8869\n",
      "Epoch 8/10\n",
      "726/726 [==============================] - 928s 1s/step - loss: 0.6838 - accuracy: 0.5670 - val_loss: 0.5595 - val_accuracy: 0.8084\n",
      "Epoch 9/10\n",
      "726/726 [==============================] - 905s 1s/step - loss: 0.6828 - accuracy: 0.5656 - val_loss: 0.4468 - val_accuracy: 0.9537\n",
      "Epoch 10/10\n",
      "726/726 [==============================] - 786s 1s/step - loss: 0.6824 - accuracy: 0.5649 - val_loss: 0.4403 - val_accuracy: 0.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a83a977c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# network.fit(train_data, epochs=20, validation_data=test_data, callbacks=EarlyStopping(patience=3))\n",
    "\n",
    "train_data = Dataset(train_csv, train_dir, batch_size=32, resize=[128, 128])\n",
    "test_data = Dataset(test_csv, test_dir, batch_size=32, resize=[128, 128])\n",
    "\n",
    "siamese.fit(\n",
    "    train_data,\n",
    "    validation_data = test_data,\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'siamese' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m siamese\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39msiamese_model1.hdf5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m siamese\u001b[39m.\u001b[39msave_weights(\u001b[39m\"\u001b[39m\u001b[39msiamese_model1_weight.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'siamese' is not defined"
     ]
    }
   ],
   "source": [
    "siamese.save(\"siamese_model1.hdf5\")\n",
    "siamese.save_weights(\"siamese_model1_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 68s 375ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8708989 ],\n",
       "       [0.9385685 ],\n",
       "       [0.89968365],\n",
       "       ...,\n",
       "       [0.49877053],\n",
       "       [0.46944293],\n",
       "       [0.5098684 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 65s 359ms/step - loss: 0.4403 - accuracy: 0.8192\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m siamese\u001b[39m.\u001b[39;49mevaluate(test_data, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mflatten()[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "siamese.evaluate(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5460352]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = \"sign_data_ver1/test/049/01_049.png\"\n",
    "img1 = cv2.imread(test1, cv2.IMREAD_GRAYSCALE)\n",
    "img1 = cv2.resize(img1, (128 , 128))\n",
    "\n",
    "test2 = \"sign_data_ver1/test/050/12_050.png\"\n",
    "img2 = cv2.imread(test2, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.resize(img2, (128 , 128))\n",
    "\n",
    "siamese.predict([img1.reshape((1, 128, 128)), \n",
    "                img2.reshape((1, 128, 128))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "Exception encountered when calling layer \"lambda\" (type Lambda).\n\nunknown opcode\n\nCall arguments received by layer \"lambda\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)']\n  • mask=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[0;32m      3\u001b[0m \u001b[39m# model = load_model('siamese_model1.h5')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39msiamese_model1.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39meuclidean_distance\u001b[39;49m\u001b[39m'\u001b[39;49m: euclidean_distance})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:/Users/mapan/AppData/Local/Temp/ipykernel_15376/1591977798.py:2\u001b[0m, in \u001b[0;36meuclidean_distance\u001b[1;34m(vects)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: Exception encountered when calling layer \"lambda\" (type Lambda).\n\nunknown opcode\n\nCall arguments received by layer \"lambda\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)']\n  • mask=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# model = load_model('siamese_model1.h5')\n",
    "model = load_model('siamese_model1.h5', custom_objects={'euclidean_distance': euclidean_distance})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac209536f6acf79e580d00c1ac3090d6f4178d82fa7a9c4f4edd3c5b57d297d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
