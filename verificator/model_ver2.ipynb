{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "gen = [glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset1/real/*.*'),\n",
    "       glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset2/real/*.*'),\n",
    "       glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset3/real/*.*'),\n",
    "       glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset4/real1/*.*')]\n",
    "                 \n",
    "forg = [glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset1/forge/*.*'),\n",
    "        glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset2/forge/*.*'),\n",
    "        glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset3/forge/*.*'),\n",
    "        glob.glob('sign_data_ver2/Dataset_Signature_Final/Dataset/dataset4/forge/*.*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "# gen = glob.glob(\"../input/handwritten-signatures/sample_Signature/sample_Signature/genuine/*.*\")\n",
    "# forg = glob.glob(\"../input/handwritten-signatures/sample_Signature/sample_Signature/forged/*.*\")\n",
    "# ../input/handwritten-signatures/sample_Signature/sample_Signature/forged/NFI-00101014.png\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for data in range(len(gen)):\n",
    "    for i in gen[data]:\n",
    "        if data == 3:\n",
    "            image = cv2.imread(i)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            test_data.append(image)\n",
    "            test_labels.append(0)\n",
    "        else:\n",
    "            image = cv2.imread(i)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            train_data.append(image)\n",
    "            train_labels.append(0) #genuine = 0\n",
    "        \n",
    "for data in range(len(forg)):\n",
    "    for j in forg[data]:\n",
    "        if data == 3:\n",
    "            image = cv2.imread(j)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            test_data.append(image)\n",
    "            test_labels.append(1)\n",
    "        else:\n",
    "            image = cv2.imread(j)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            train_data.append(image)\n",
    "            train_labels.append(1) #forged = 1\n",
    "\n",
    "train_data = np.array(train_data)/255.0\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_data = np.array(test_data)/255.0\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_data,train_labels = shuffle(train_data,train_labels)\n",
    "\n",
    "test_data,test_labels = shuffle(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, Conv2D, BatchNormalization\n",
    "# from keras.layers.normalization import Normalization\n",
    "from keras.regularizers import l2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# network = Sequential()\n",
    "\n",
    "# network.add(Conv2D(64,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "# network.add(MaxPooling2D(3,3))\n",
    "# network.add(Conv2D(32,(3,3),activation='relu'))\n",
    "# network.add(MaxPooling2D(2,2))\n",
    "# network.add(Flatten())\n",
    "# network.add(Dense(128,activation = 'relu'))\n",
    "# network.add(Dropout(rate=0.3))\n",
    "# network.add(Dense(1, activation = 'softmax'))\n",
    "\n",
    "# network = Sequential()\n",
    "# network.add(Conv2D(16, (3,3), activation='relu', input_shape=(224,224,3)))\n",
    "# network.add(Conv2D(32, (3,3), activation='relu'))\n",
    "# network.add(Conv2D(16, (3,3), activation='relu'))\n",
    "\n",
    "# network.add(Flatten())\n",
    "\n",
    "# network.add(Dense(128, activation='relu'))\n",
    "# network.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Sequential()\n",
    "# # network.add(Convolution2D(96, 11, 11, activation='relu', name='conv1_1', subsample=(3, 3), input_shape= (224, 224, 3), \n",
    "# #                     init='glorot_uniform', dim_ordering='tf'))\n",
    "\n",
    "# network.add(Conv2D(96, (11,11), (3,3), input_shape = (224, 244, 3), activation=\"relu\", kernel_initializer=\"glorot_uniform\"), )\n",
    "# network.add(BatchNormalization(epsilon=1e-06, momentum=0.9))\n",
    "# network.add(MaxPooling2D((3,3), strides=(2, 2)))    \n",
    "# network.add(ZeroPadding2D((2, 2)))\n",
    "\n",
    "# # network.add(Convolution2D(256, 5, 5, activation='relu', name='conv2_1', subsample=(1, 1), init='glorot_uniform',  dim_ordering='tf'))\n",
    "# network.add(Conv2D(256, (5,5), (1,1), activation=\"relu\", kernel_initializer=\"glorot_uniform\"), )\n",
    "# network.add(BatchNormalization(epsilon=1e-06, momentum=0.9))\n",
    "# network.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
    "# network.add(Dropout(0.3))# added extra\n",
    "# network.add(ZeroPadding2D((1, 1)))\n",
    "\n",
    "# # network.add(Convolution2D(384, 3, 3, activation='relu', name='conv3_1', subsample=(1, 1), init='glorot_uniform',  dim_ordering='tf'))\n",
    "# network.add(Conv2D(384, (3,3), (1,1), activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "# network.add(ZeroPadding2D((1, 1)))\n",
    "\n",
    "# # network.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2', subsample=(1, 1), init='glorot_uniform', dim_ordering='tf'))    \n",
    "# network.add(Conv2D(256, (3,3), (1,1), activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "# network.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
    "# network.add(Dropout(0.3))# added extra\n",
    "# #    model.add(SpatialPyramidPooling([1, 2, 4]))\n",
    "# network.add(Flatten(name='flatten'))\n",
    "# network.add(Dense(1024, activation='relu', bias_regularizer=l2(0.005), kernel_initializer='glorot_uniform'))\n",
    "# network.add(Dropout(0.5))\n",
    "\n",
    "# network.add(Dense(128, activation='relu', bias_regularizer=l2(0.005), kernel_initializer='glorot_uniform')) # softmax changed to relu\n",
    "\n",
    "# network.compile(optimizer=RMSprop(learning_rate=1e-4, rho=0.9, epsilon=1e-08),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "# network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "# base_model = tf.keras.applications.MobileNetV3Large(input_shape=(224, 224, 3),\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet'\n",
    "#                                                )\n",
    "# base_model.trainable = False\n",
    "                                               \n",
    "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# prediction_layer = keras.layers.Dense(1)\n",
    "\n",
    "# network = tf.keras.Sequential([\n",
    "#   base_model,\n",
    "#   global_average_layer,\n",
    "#   prediction_layer\n",
    "# ])\n",
    "\n",
    "# base_learning_rate = 0.001\n",
    "# network.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "network.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 46/513 [=>............................] - ETA: 2:06 - loss: 6.6327 - accuracy: 0.5652"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\mapan3\\Desktop\\Signature Detector\\model_ver2.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/mapan3/Desktop/Signature%20Detector/model_ver2.ipynb#ch0000014?line=17'>18</a>\u001b[0m model1 \u001b[39m=\u001b[39m Sequential([base_model1, global_average_layer, prediction_layer])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/mapan3/Desktop/Signature%20Detector/model_ver2.ipynb#ch0000014?line=18'>19</a>\u001b[0m model1\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m),loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Users/mapan3/Desktop/Signature%20Detector/model_ver2.ipynb#ch0000014?line=19'>20</a>\u001b[0m progress1 \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39;49mfit(train_data,train_labels, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,epochs\u001b[39m=\u001b[39;49mEPOCHS, callbacks\u001b[39m=\u001b[39;49mcallback_early_stop_reduceLROnPlateau,validation_split\u001b[39m=\u001b[39;49m\u001b[39m.05\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/mapan3/Desktop/Signature%20Detector/model_ver2.ipynb#ch0000014?line=21'>22</a>\u001b[0m base_model2 \u001b[39m=\u001b[39m MobileNetV3Small(input_shape\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m), include_top\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/mapan3/Desktop/Signature%20Detector/model_ver2.ipynb#ch0000014?line=22'>23</a>\u001b[0m model2 \u001b[39m=\u001b[39m Sequential([base_model2, global_average_layer, prediction_layer])\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mapan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNetV2, MobileNetV3Small, Xception\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1)\n",
    "\n",
    "callback_early_stop_reduceLROnPlateau=[earlyStopping]\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = keras.layers.Dense(1)\n",
    "\n",
    "base_model1 = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "model1 = Sequential([base_model1, global_average_layer, prediction_layer])\n",
    "model1.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "progress1 = model1.fit(train_data,train_labels, batch_size=BATCH_SIZE,epochs=EPOCHS, callbacks=callback_early_stop_reduceLROnPlateau,validation_split=.05)\n",
    "\n",
    "base_model2 = MobileNetV3Small(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "model2 = Sequential([base_model2, global_average_layer, prediction_layer])\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "progress2 = model2.fit(train_data,train_labels, batch_size=BATCH_SIZE,epochs=EPOCHS, callbacks=callback_early_stop_reduceLROnPlateau,validation_split=.05)\n",
    "\n",
    "base_model3 = Xception(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "model3 = Sequential([base_model3, global_average_layer, prediction_layer])\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "progess3 = model3.fit(train_data,train_labels, batch_size=BATCH_SIZE,epochs=EPOCHS, callbacks=callback_early_stop_reduceLROnPlateau,validation_split=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1)\n",
    "\n",
    "callback_early_stop_reduceLROnPlateau=[earlyStopping]\n",
    "\n",
    "\n",
    "EPOCHS = 40\n",
    "BS = 1\n",
    "progess = network.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=callback_early_stop_reduceLROnPlateau,validation_split=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = progess.history['accuracy']\n",
    "val_acc = progess.history['val_accuracy']\n",
    "loss = progess.history['loss']\n",
    "val_loss = progess.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()\n",
    " \n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 9s 1s/step - loss: 0.6508 - accuracy: 0.6389\n",
      "Test Accuracy: 0.6388888955116272\n"
     ]
    }
   ],
   "source": [
    "# pred = network.predict(test_data)\n",
    "\n",
    "# pred\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy_score(pred.argmax(axis=1), test_labels)\n",
    "\n",
    "test_loss, test_acc = network.evaluate(test_data, test_labels, verbose=1) \n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save(\"ver2_testmodel1.h5\")  #saving the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad494814622fc7a7adb6a90fabdf7f021a85d8560d459ea24a8b4c0a76499cdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
